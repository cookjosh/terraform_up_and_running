## Chapter 2 - Getting Started with Terraform
- resources are defined with the convention of `resource` `<provider_resource>` `<name>` where `provider` refers to the backend provider (in this case AWS), `resource` refers to a provider's product (eg EC2 instance), and `name` which can be referenced by other parts of the code.
- `user_data_replace_on_change = true` - This parameter terminates the original instance and launches a replacement. This is because terraform will typically only update the original in place but `user_data` is only run on initial boot!
- AWS does not allow traffic to/from an instance by default, so a security group is required.
    - For an `instance` to use a sg, it needs a `vpc_security_group_ids` argument.
- Terraform refers to `expressions` as anything that returns a value.
    - `Literals` are the simplest type (strings and numbers)
    - `references` can be used to refer to other parts of the code, like a `resource attribute reference` which uses syntax like `<provider>_<type>.<name>.<attribute>`
        - Remember that resources have `<name>` in their definition syntax that can be referred to elsewhere (like by a `resource attribute reference`)
        - `<attribute>` can be an argument (eg name) or something "exported" by the resource (eg `id` in the case of security groups).
- References between resources creates "implicit dependencies" on each other, so terraform creates a dependency graph to determine in what order to create resources (if all applied from scratch) or in parallel if possible.
- Like in other languages, we can assign values to variables to be used throughout our code and minimize repetitiveness. Variables are delcared using syntax like `variable "NAME" { [CONFIG ...] }`
    - The body of the variable declaration (in the config brackets) can contain:
        - `description` - can be used as documentation in code but also is output to terminal when running `plan` or `apply`.
        - `default` - a way to set a "fallback" value for the variable.
        - `type` - set constraints for what can be passed in.
        - `validation` - custom input validation rules (eg char length)
        - `sensitive` - if `true`, terraform won't log it when you run `plan` or `apply`, so useful for things like secrets.
    - After declaring a variable, we can reference it with the syntax `var.<VARIABLE_NAME>` and use this in place of hardcoding the same value in multiple places!
    - They can also be used in a string literal (like our `user_data` script) using an `interpolation` with the syntax of `${...}`.
- We can not only create input variables as above but also `output` variables using syntax like `output "<NAME>" { value = <VALUE> [CONFIG...]}`.
    - `name` is how we can reference it elsewhere in the code.
    - `value` can be any terraform expression to be outputted.
    - `config` can contain the parameters:
        - `description` - similar to how it's used in `variable` parameterss
        - `sensitive` - similar to `variable`
        - `depends_on` - a way to tell terraform there is a dependency between resources that it might not pick up through its own dependency graph.
    - outputs can be outputted without `plan` or `apply` by using `terraform output`.
- AWS Auto Scaling Group (ASG) is used to manage the size of the cluster based on factors like individual server health, traffic, etc...
    - They require a `launch configuration` which is declared similar to an `aws_instance` resource, but does use slightly different parameters (`image_id` vs `ami` respectively).
        - Since they automatically launch new instances as needed, you don't need the `user_data_replace_on_change` parameter previously in the notes!
    - Defining the ASG has a `min_` and `max_size` to have boundaries on how many instances it will create.
    - `launch configurations` have a `lifecycle` parameter which is necessary to allow for updates. Because the `aws_autoscaling_group` references the `launch configuration`, deleting and creating the launch config is not possible.
        - This allows terraform to create a new `launch configuration` first, update the reference within the `aws_autoscaling_group`, then delete the old one.
    - ASGs also need a `subnet_ids` parameter so they know what VPC subnets to deploy the EC2 instances.
- `data` sources allow us to get read-only info from the provider to be used in our code as a reference, kind of like how variables are used! Their syntax is `data "<PROVIDER>_<TYPE>" "<NAME>" { [CONFIG...] }`. `type` in this case refereces to the data source you want to use (eg `vpc`).
    - Elsewhere in code, they can be referenced with the syntax `data.<PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>`.
    - Attributes of `data` sources can also be used within other `data` sources, for example getting `aws_subnets` data can use something like `data.aws_vpc.default.id` within its `filter` config block to retrieve subnet information from the default vpc (See code for this in action).
- Elastic Load Balancers (ELBs) allow you to have one resource that as the ingress point for your cluster and distributes traffic across them. This provides your users a single IP/URL to use vs individual IPs for each EC2 instance. There are three types:
    - Application Load Balancer (ALB) - best suited for HTTP(S) traffic.
    - Network Load Balancer (NLB) - best for TCP, UDP, and TLS, and can scale to load faster than an ALB (designed to scale for tens of millions of requests per second).
    - Classic Load Balancer (CLB) - "legacy" load balancer.
- ALBs 
    - They consist of several parts:
        - Listener - specific port and protocol it listens on.
        - Listener Rule - takes requests into the listener and sends them to specific target groups based on paths or hostname matches.
        - Target Groups - One or more servers that receive requests. The Group assess the health of its servers and only sends requests to healthy nodes.
    - They are created by defining a few resources: the ALB itself (`aws_lb` with `application` defined in parameters), the `aws_lb_listener`, the `aws_lb_listener_rule`, the `aws_lb_target_group`, and an `aws_security_group` for the ALB.
    - We can change our `output` for public IP to the `dns_name` of our `aws_lb` resource, so that we now get the singular, public address the ALB will use to front our cluster!
    
## Chapter 3 - How to Manage Terraform State
- Running `terraform apply` records information about the current state of infrastructure in a terraform `state file`.
    - By default, this file is created in your working directory as `terraform.tfstate` and is a JSON file that maps resources in your config to the real world resources in AWS.
    - Running `plan` is essentially diffing your code against the deployed infrastructure.
    - Never edit this file by hand!
    - Some challenges arise when using terraform as a team: how to use shared storage for state files, how to lock state files when someone's using it, and how to isolate state files between environments (dev vs prod).
- **Shared Storage for State Files**
    - The best way to manage shared storage for state files is to use remote `backends`; the built-in way terraform determines how to load and store state.
    - Through chapter 2, we used a `local backend`, a state file saved to local disk. In a distributed team, we would want to use something `remote` and accessible to everyone, such as S3. They solve common problems such as:
        - **Manual error** - the state file will be loaded and then stored again after each `plan` and `apply`, preventing any manual error.
        - **Locking** - many remote backends support some type of locking feature, allowing for one individual to run `apply` and affect changes at a time.
        - **Secrets** - most remote backends support in-transit and at-rest encryption of the state file, as well as IAM policies for acess control. Additionally, using a remote backend prevents storing secrets in plain-text on local disk.
    - S3 offers a number of benefits and will be used through this course.
    - Defining an S3 bucket is similar to other `resources` but a few notes:
        - The `bucket` parameter is the real world name we're giving to the bucket, and this must be *globally unique* to all AWS customers!
        - We can set a `prevent_destory` policy within the `lifecycle` parameter to prevent an `apply` from deleting that resource (terraform will exit with an error).
        - We need to define other resources to enable feaures like versioning, encryption, blocking public access...
    - DynamoDB tables are used for locking the state files while in use.
        - When creating this resource, it *must* have a primary key called `LockID` (exact spelling and capitalization).
    - Terraform requires a `backend` configuration so that it knows to store your state file in your S3 bucket instead of locally on disk!
        - This is done by adding a `terraform` block that configures terraform itself, and uses the syntax `terraform { backend "<BACKEND_NAME>" { [CONFIG...] }}` where `BACKEND_NAME` is the backend we want to use (eg S3). See the code for more detail!
    - After configuring the bucket and `terraform` block to use the bucket for remote state file storage, if we run `terraform init` again, it will then begin to store the state file in the bucket and use in this configuration.
    - Interestingly, we had to write code to create the bucket and DynamoDB table and use a local backend for that state file. Then we wrote code to add a backend for the bucket and table, then reinitialize terraform to use it.
        - The good news this is a one time process, and the rest of our code can use this `backend` configuration from the get go.
    - Note that we also have to manually write the `terraform` backend configuration for every module (learned in later lessons) and can't use variables. We also have to have a unique key (file path within the bucket) for every module we create, so be careful not to just copy and paste the backend config verbatim.
- **State File Isolation**
    - So far through the book, we've written all of our tf code in one file and folder, using one backend config, which stores **all** of our state in a single file. This means one mistake could break our entire infrastructure.
    - There are two ways we can chose to isolate state files, either by `Isolation via workspaces` or `isolation via file layout`.
    - **Isolation via Workspaces**
        - By default, terraform starts with a single workspace called `default`, and this workspace stores state files in the `key` you specify in your backend configuration.
        - You can use `terraform workspace new {workspace_name}` to create new isolated workspace environments, and running `apply` on the same configuration files but in different workspaces will create new resources.
        - Creating workspaces and applying configs creates an `env` folder in your s3 bucket, with child folders for each workspace that contain their own state files.
        - You can switch between resources with `terraform workspace select {workspace_name}`.
        - This is a nice way to test changes on a deployed module without affecting running infrastructure!
        - Drawbacks include:
            - Using the same credentials for all workspaces, which prevents true isolation.
            - Workspaces are not visible in the code, so real world infrastructure may be different than the codebase.
    - **Isolation via File Layout**
        - Full isolation can be achieved by putting config files for different environments (eg prod and dev) in their own folders, and by configuring a different backend for each environment that can have different authentication and access controls.
            - [An example can be found here](https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa#:~:text=Here%E2%80%99s%20the%20file%20layout%20for%20my%20typical%20Terraform%20project%3A)
            - To take it further, you could also put separate "components" into their own folders like a `mgmt` folder for more static resources (eg VPCs, subnets, etc...) and `services` (eg a frequently modified webapp) so that constant changes in one component won't run the risk of modifying static infrastructure.
        - Terraform doesn't care about filenames but it is useful to follow some convention for your team. Examples would be:
            - `variables.tf` for input vars, `outputs.tf` for output vars, `main.tf` for resources and data sources, etc... You can go further such as `providers.tf` for quick reference of provider information.
        - This layout has some advantages like clear understanding of how components are deployed and in what environments, and there's decent isolation to minimize the blast radius of any mistakes.
            - However a drawback is that now `apply` has to be run in each module individually to create your entire infrastructure.
    - **`terraform_remote_state` Data Source**
        - This data source is useful to allow us to get a state file of other modules to use that information in a module we might be currently working in!
        - For this topic we wil create a MySQL db on AWS RDS. Important notes:
            - The DB creation will require a username and password passed in. Since we want to avoid secrets in plain text, for now we will create variables in `variables.tf` and pass those values in via the command line for example `export TF_VAR_db_username=<username>`
            - We also create output variables about the DB that we want our webserver cluster to take as input so it can connect to the DB. We do this by adding a `data` block to the `main.tf` file for the cluster and pointing it to the statefile for the DB.
            - We also use a `templatefile` to read in data from a bash script, as opposed to inline Bash, that was formerly in the `user_data` parameter of `main.tf`