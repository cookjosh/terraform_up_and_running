# Overall Notes
This file is the overall notes from my progression through the book, which was originally [this series of blogposts](https://blog.gruntwork.io/a-comprehensive-guide-to-terraform-b3d32832baca#.b6sun4nkn). I've linked the blogpost throughout for relevant images as well. For each chapter, I broke out the individual chapter notes into their own file in their respective chapter folder in the repo.

## Chapter 2 - Getting Started with Terraform
- resources are defined with the convention of `resource` `<provider_resource>` `<name>` where `provider` refers to the backend provider (in this case AWS), `resource` refers to a provider's product (eg EC2 instance), and `name` which can be referenced by other parts of the code.
- `user_data_replace_on_change = true` - This parameter terminates the original instance and launches a replacement. This is because terraform will typically only update the original in place but `user_data` is only run on initial boot!
- AWS does not allow traffic to/from an instance by default, so a security group is required.
    - For an `instance` to use a sg, it needs a `vpc_security_group_ids` argument.
- Terraform refers to `expressions` as anything that returns a value.
    - `Literals` are the simplest type (strings and numbers)
    - `references` can be used to refer to other parts of the code, like a `resource attribute reference` which uses syntax like `<provider>_<type>.<name>.<attribute>`
        - Remember that resources have `<name>` in their definition syntax that can be referred to elsewhere (like by a `resource attribute reference`)
        - `<attribute>` can be an argument (eg name) or something "exported" by the resource (eg `id` in the case of security groups).
- References between resources creates "implicit dependencies" on each other, so terraform creates a dependency graph to determine in what order to create resources (if all applied from scratch) or in parallel if possible.
- Like in other languages, we can assign values to variables to be used throughout our code and minimize repetitiveness. Variables are delcared using syntax like `variable "NAME" { [CONFIG ...] }`
    - The body of the variable declaration (in the config brackets) can contain:
        - `description` - can be used as documentation in code but also is output to terminal when running `plan` or `apply`.
        - `default` - a way to set a "fallback" value for the variable.
        - `type` - set constraints for what can be passed in.
        - `validation` - custom input validation rules (eg char length)
        - `sensitive` - if `true`, terraform won't log it when you run `plan` or `apply`, so useful for things like secrets.
    - After declaring a variable, we can reference it with the syntax `var.<VARIABLE_NAME>` and use this in place of hardcoding the same value in multiple places!
    - They can also be used in a string literal (like our `user_data` script) using an `interpolation` with the syntax of `${...}`.
- We can not only create input variables as above but also `output` variables using syntax like `output "<NAME>" { value = <VALUE> [CONFIG...]}`.
    - `name` is how we can reference it elsewhere in the code.
    - `value` can be any terraform expression to be outputted.
    - `config` can contain the parameters:
        - `description` - similar to how it's used in `variable` parameterss
        - `sensitive` - similar to `variable`
        - `depends_on` - a way to tell terraform there is a dependency between resources that it might not pick up through its own dependency graph.
    - outputs can be outputted without `plan` or `apply` by using `terraform output`.
- AWS Auto Scaling Group (ASG) is used to manage the size of the cluster based on factors like individual server health, traffic, etc...
    - They require a `launch configuration` which is declared similar to an `aws_instance` resource, but does use slightly different parameters (`image_id` vs `ami` respectively).
        - Since they automatically launch new instances as needed, you don't need the `user_data_replace_on_change` parameter previously in the notes!
    - Defining the ASG has a `min_` and `max_size` to have boundaries on how many instances it will create.
    - `launch configurations` have a `lifecycle` parameter which is necessary to allow for updates. Because the `aws_autoscaling_group` references the `launch configuration`, deleting and creating the launch config is not possible.
        - This allows terraform to create a new `launch configuration` first, update the reference within the `aws_autoscaling_group`, then delete the old one.
    - ASGs also need a `subnet_ids` parameter so they know what VPC subnets to deploy the EC2 instances.
- `data` sources allow us to get read-only info from the provider to be used in our code as a reference, kind of like how variables are used! Their syntax is `data "<PROVIDER>_<TYPE>" "<NAME>" { [CONFIG...] }`. `type` in this case refereces to the data source you want to use (eg `vpc`).
    - Elsewhere in code, they can be referenced with the syntax `data.<PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>`.
    - Attributes of `data` sources can also be used within other `data` sources, for example getting `aws_subnets` data can use something like `data.aws_vpc.default.id` within its `filter` config block to retrieve subnet information from the default vpc (See code for this in action).
- Elastic Load Balancers (ELBs) allow you to have one resource that as the ingress point for your cluster and distributes traffic across them. This provides your users a single IP/URL to use vs individual IPs for each EC2 instance. There are three types:
    - Application Load Balancer (ALB) - best suited for HTTP(S) traffic.
    - Network Load Balancer (NLB) - best for TCP, UDP, and TLS, and can scale to load faster than an ALB (designed to scale for tens of millions of requests per second).
    - Classic Load Balancer (CLB) - "legacy" load balancer.
- ALBs 
    - They consist of several parts:
        - Listener - specific port and protocol it listens on.
        - Listener Rule - takes requests into the listener and sends them to specific target groups based on paths or hostname matches.
        - Target Groups - One or more servers that receive requests. The Group assess the health of its servers and only sends requests to healthy nodes.
    - They are created by defining a few resources: the ALB itself (`aws_lb` with `application` defined in parameters), the `aws_lb_listener`, the `aws_lb_listener_rule`, the `aws_lb_target_group`, and an `aws_security_group` for the ALB.
    - We can change our `output` for public IP to the `dns_name` of our `aws_lb` resource, so that we now get the singular, public address the ALB will use to front our cluster!
    
## Chapter 3 - How to Manage Terraform State
- Running `terraform apply` records information about the current state of infrastructure in a terraform `state file`.
    - By default, this file is created in your working directory as `terraform.tfstate` and is a JSON file that maps resources in your config to the real world resources in AWS.
    - Running `plan` is essentially diffing your code against the deployed infrastructure.
    - Never edit this file by hand!
    - Some challenges arise when using terraform as a team: how to use shared storage for state files, how to lock state files when someone's using it, and how to isolate state files between environments (dev vs prod).
- **Shared Storage for State Files**
    - The best way to manage shared storage for state files is to use remote `backends`; the built-in way terraform determines how to load and store state.
    - Through chapter 2, we used a `local backend`, a state file saved to local disk. In a distributed team, we would want to use something `remote` and accessible to everyone, such as S3. They solve common problems such as:
        - **Manual error** - the state file will be loaded and then stored again after each `plan` and `apply`, preventing any manual error.
        - **Locking** - many remote backends support some type of locking feature, allowing for one individual to run `apply` and affect changes at a time.
        - **Secrets** - most remote backends support in-transit and at-rest encryption of the state file, as well as IAM policies for acess control. Additionally, using a remote backend prevents storing secrets in plain-text on local disk.
    - S3 offers a number of benefits and will be used through this course.
    - Defining an S3 bucket is similar to other `resources` but a few notes:
        - The `bucket` parameter is the real world name we're giving to the bucket, and this must be *globally unique* to all AWS customers!
        - We can set a `prevent_destory` policy within the `lifecycle` parameter to prevent an `apply` from deleting that resource (terraform will exit with an error).
        - We need to define other resources to enable feaures like versioning, encryption, blocking public access...
    - DynamoDB tables are used for locking the state files while in use.
        - When creating this resource, it *must* have a primary key called `LockID` (exact spelling and capitalization).
    - Terraform requires a `backend` configuration so that it knows to store your state file in your S3 bucket instead of locally on disk!
        - This is done by adding a `terraform` block that configures terraform itself, and uses the syntax `terraform { backend "<BACKEND_NAME>" { [CONFIG...] }}` where `BACKEND_NAME` is the backend we want to use (eg S3). See the code for more detail!
    - After configuring the bucket and `terraform` block to use the bucket for remote state file storage, if we run `terraform init` again, it will then begin to store the state file in the bucket and use in this configuration.
    - Interestingly, we had to write code to create the bucket and DynamoDB table and use a local backend for that state file. Then we wrote code to add a backend for the bucket and table, then reinitialize terraform to use it.
        - The good news this is a one time process, and the rest of our code can use this `backend` configuration from the get go.
    - Note that we also have to manually write the `terraform` backend configuration for every module (learned in later lessons) and can't use variables. We also have to have a unique key (file path within the bucket) for every module we create, so be careful not to just copy and paste the backend config verbatim.
- **State File Isolation**
    - So far through the book, we've written all of our tf code in one file and folder, using one backend config, which stores **all** of our state in a single file. This means one mistake could break our entire infrastructure.
    - There are two ways we can chose to isolate state files, either by `Isolation via workspaces` or `isolation via file layout`.
    - **Isolation via Workspaces**
        - By default, terraform starts with a single workspace called `default`, and this workspace stores state files in the `key` you specify in your backend configuration.
        - You can use `terraform workspace new {workspace_name}` to create new isolated workspace environments, and running `apply` on the same configuration files but in different workspaces will create new resources.
        - Creating workspaces and applying configs creates an `env` folder in your s3 bucket, with child folders for each workspace that contain their own state files.
        - You can switch between resources with `terraform workspace select {workspace_name}`.
        - This is a nice way to test changes on a deployed module without affecting running infrastructure!
        - Drawbacks include:
            - Using the same credentials for all workspaces, which prevents true isolation.
            - Workspaces are not visible in the code, so real world infrastructure may be different than the codebase.
    - **Isolation via File Layout**
        - Full isolation can be achieved by putting config files for different environments (eg prod and dev) in their own folders, and by configuring a different backend for each environment that can have different authentication and access controls.
            - [An example can be found here](https://blog.gruntwork.io/how-to-manage-terraform-state-28f5697e68fa#:~:text=Here%E2%80%99s%20the%20file%20layout%20for%20my%20typical%20Terraform%20project%3A)
            - To take it further, you could also put separate "components" into their own folders like a `mgmt` folder for more static resources (eg VPCs, subnets, etc...) and `services` (eg a frequently modified webapp) so that constant changes in one component won't run the risk of modifying static infrastructure.
        - Terraform doesn't care about filenames but it is useful to follow some convention for your team. Examples would be:
            - `variables.tf` for input vars, `outputs.tf` for output vars, `main.tf` for resources and data sources, etc... You can go further such as `providers.tf` for quick reference of provider information.
        - This layout has some advantages like clear understanding of how components are deployed and in what environments, and there's decent isolation to minimize the blast radius of any mistakes.
            - However a drawback is that now `apply` has to be run in each module individually to create your entire infrastructure.
    - **`terraform_remote_state` Data Source**
        - This data source is useful to allow us to get a state file of other modules to use that information in a module we might be currently working in!
        - For this topic we wil create a MySQL db on AWS RDS. Important notes:
            - The DB creation will require a username and password passed in. Since we want to avoid secrets in plain text, for now we will create variables in `variables.tf` and pass those values in via the command line for example `export TF_VAR_db_username=<username>`
            - We also create output variables about the DB that we want our webserver cluster to take as input so it can connect to the DB. We do this by adding a `data` block to the `main.tf` file for the cluster and pointing it to the statefile for the DB.
            - We also use a `templatefile` to read in data from a bash script, as opposed to inline Bash, that was formerly in the `user_data` parameter of `main.tf`

## Chapter 4 - How to Create Reusable Infrastructure with Terraform Modules
- At the end of chapter 3, we created [this architecture](https://blog.gruntwork.io/how-to-create-reusable-infrastructure-with-terraform-modules-25526d65f73d#:~:text=In%20the%20previous%20post%2C%20you%20deployed%20architecture%20that%20looks%20like%20this) in our `stage` folder, which if we want a `stage` and prod environment, would mean we'd have to copy this code over to the other environment.
    - These environments would be largely identical but with some slight differences, such as possibly having smaller servers in `stage` to save money.
- Like general-purpose programming languages that the idea of reusable *functions*, terraform has `modules` that can be reused throughout your code!
    - For example, if we have a "standard" webserver-cluster in our environments, we can break this out into a module that can then be pulled into the code for each environment and given minor tweaks to fit that environment.
    - This is key to allowing terraform to be reusable, maintainable, and testable!
- **Module Basics**
    - In fact, a `module` in terraform is any set of configuration files within a folder. So in effect, we've actually been creating modules this entire time. But because we're running apply directly on a module, it's considered a `root module`.
        - What we really want to do is create `reusable modules`, those that are *meant* to be used within other modules.
    - Using `stage/services/webserver-cluster`, we're going to explore creating reusable modules.
        - First we want to remove the `provider` definition in `main.tf` as *providers* should be defined in root modules.
        - Modules use the syntax `module "<NAME>" { source = "<SOURCE>" [CONFIG...]} where NAME is how we will refer to this module throughout our code, SOURCE is the path of the module code, and CONFIG is specific arguments
        - Checking the code in this repo, you can see that we've imported the `webserver-cluster` module into both `stage` and a new environment `prod`. Anytime we add a module or modify a module's `source`, we'll want to run `init` before `plan` or `apply`. You can see when we `init` in `prod` for example, one of the console output lines is actually initializing the module we want to import!
- **Module Inputs**
    - Like a programming language's functions can take input variables, so can modules in the form of their parameters. We can also create a `variables.tf` in a module path to define these inputs.
    - At the end of chapter 3, we hardcoded all of the cluster resource names into `main.tf` that we moved to the new module folder, so if we were to run apply in both `stage` and `prod`, we'd have naming conflicts. So we will want to use `var.cluster_name` instead.
    - Since we created these variables in the module's `variables.tf` file, we can pass values in when we import the module in each environment's `main.tf` by passing values for each variable in the module import. In the `module` definition `main.tf` we use `var.variable_name` to pass it back to itself. See the code for how that works!
- **Module Locals**
    - For some values, using variables might lead to issues because their value can be affected elsewhere in the codebase by you or another user. For example, the `cluster_name` variable can change by accident. We might want some values to remain constant, such as the listener port (80) and not be editable, so we can use the concept of `locals`.
    - Locals are only visible within the module and have no impact on others, and they can't be overridden from outside of that individual module. They use the syntax `local.<NAME>`. We will edit some of the network information for our http listener and alb ingress/egress blocks with locals! See the code.
- **Module Outputs**
    - ASGs can be configured to scale up or down on a schedule using `scheduled actions`, which can be a nice feature if you have repeated timeframes of increased traffic.
        - Note that this might not be best defined in a module, since the module is imported into `stage` and `prod`, and scheduled scaling might not be necessary in a staging environment. So far now we will explore this in the prod environment only.
        - When we create an output in the modules `outputs.tf`, they can be accessed in an environment's `outputs.tf` by defining an output and using the `module.<MODULE_NAME>.<OUTPUT_NAME>` syntax.
- **Module Gotchas**
    - We may want to be aware of two things when creating modules: File paths and inline blocks.
    - File Paths - the `user_data.sh` file is now in our modules folder, and terraform's `templatefile` function reads files from the *relative path* on local disk, meaning when we first created the module, neither environment would be able to successfully call it.
        - We can instead user a `path reference` (`path.<TYPE>`) such as `path.module`. In this case it will use the filesystem path of the module *where the expression is defined*.
        - So in our module's `main.tf` where we define the path of our script, we want to prefix with our path type like so: `${path.module}/user_data.sh` so that other environments know this file is located within the module definition path!
    - Inline blocks - some configuration for resources can either be inline block-defined or defined as separate resources. For example, the `ingress` and `egress` definitions we've done for the security group resource can actually be their own separate resources `aws_security_group_rule`.
        - Mixing the two however can lead to conflict errors as they may attempt to overwrite each other, so when creating modules, it may be best to define them as separate resources. This is because the separate resources can be added anywhere whereas the inline block only applies to the module that creates the resource.
        - To further clarify, in our module we originally defined the `ingress` and `egress` in `aws_security_group alb` so users won't be able to add more rules outside of the module.
        - Changing these to their own resources then allows us in an environment `main.tf`, for example in `stage`, to define additional rules if desired when importing the module while retaining the defaults we create in the module `main.tf`
        - Had we left the original inline blocks in the module `main.tf`, creating additional during the module import would have lead to errors in the rules attempting to overwrite one another.
- Important Note: The book, for simplicity, uses on VPC for both `stage` and `prod` environments. This is not recommended or ideal in actual real world production. Misconfigurations in either environment to critical resources (like route tables) could affect traffic to and from the entire VPC affecting all environments.
    - Thus it is recommended to use separate VPCs, or even separate AWS accounts if possible, to achieve isolation between environments.
- **Module Versioning**
    - So far we created one module that is imported into both `stage` and `prod` environments. This causes an issue in that changes to the module will affect both environments, making testing changes in `stage` much more likely to affect production. A better approach would be to use `versioned modules`, with versions applying to separate environments.
    - An easy way to achieve this versioning is to store module code in a separate git repo and setting the `source` parameter of the module imports to that URL.

## Chapter 5 - Tips and Tricks: Loops, If-Statements, Deployment, and Gotchas
As a declarative language certain operations are more difficult like loops, if-statements, etc.. Luckily terraform does provide a few primitives that we will see in this chapter! We can use these in a few different loop constructs in terraform:
- **Loops with the `count` parameter** - loops over resources and modules. We will see this in action by creating a number of users with AWS IAM.
    - Every resource has `count` as a parameter. It is quite primitive and all it does on its own is define the number of copies we want to make of that resource.
    - As you can see in the code, we can use `count.index` to append the index to a value for the resource's `name` parameter as count iterates through the value we set for itself (`count = 3 name = "neo.${count.index}"`). In this instance though, each user would be named `neo.` with whatever value of the index was iterated next which may not be particularly useful.
        - Instead, we could create a variable called something like `user_names` with a default value of a list that has 3 separate names. 
        - Since terraform also has arrays (using the `Array lookup syntax`) and a length function, we can combine these with count using like so: `count = length(var.user_names) \n name = var.user_names[count.index]`. So here `count` is set to the length of the list in teh variable, and we iterate through count and use each integer back against the list as its index and the usernames are pulled in from each index.
        - What we've done now is create `aws_iam_user.example` as an array, not a single resource, so it can't be accessed with the usual syntax of `<PROVIDER>_<TYPE>.<NAME>.<ATTRIBUTE>` (a user name as `aws_iam_user.example.name`), instead we also need to use array lookup syntax on it like `<PROVIDER>_<TYPE>.<NAME>[INDEX].<ATTRIBUTE>`. See the `outputs.tf` file for examples!
    - `count` can also be used on modules just like resources. When we import a module, we can add `count` as a parameter (just like we did the with the `aws_iam_user` example), point it to a variable to get an array or list, and use `count.index` to iterate through the list the same way.
    - `count` cannot be used in inline blocks however. Consider the `tag` block of our `aws_autoscaling_group` resource. Unfortunately we cannot write code that allows users to pass in tags during creation by setting up similar logic to our previous examples here.
    - Another limitation of `count` is that, again, resources become arrays, so changing values of a resource can lead to destroying parts of the array. 
        - In our examples above, we had a `user_names` list variable that had 3 usernames within it. Say we created 3 users and user `trinity` was at index 1 (`aws_iam_user.example[1]`). If we decided we wanted to remove trinity from the list, because of her position in the list, terraform will instead rename her to morpheus and delete the original morpheus user.
        - Terraform is essentially deleting every item to the right of trinity in the list and recreating them one index position to the left.
        - The end result *looks* the same, but this can lead to data loss. A
        \gain the morpheus user is not the original user, it has been destroyed and recreated!
- **Loops with `for_each` Expressions** - The `for_each` expression allows us to loop over lists, sets, and maps to create a) multiple copies of an entire resource, b) multiple copies of an inline block within a module, or c) multiple copies a module itself.
    - THe syntax looks like `resource "<PROVIDER>_<TYPE>" "<NAME>" { for_each = <COLLECTION> [CONFIG...]}`
        - `COLLECTION` is a set or map to loop over (lists are not supported in `for_each` on a resource) and `CONFIG` consists of one or more arguments specific to that resource.
            - In `CONFIG` you can use `each.key` and `each.value` for the current item in `COLLECTION`.
        - Look at the code for the example, but when `for_each` loops over the `user_name` *set* it makes each username available under `each.value`, which we assign to `name` for each IAM user resource that is created.
            - `each.key` also contains the username(s) but is typically only used with maps and key-value pairs.
        - Using `for_each` on a resource creates a *map* of resources as opposed to one resource (or an *array* or resources as with `count`). The keys in the map are the usernames (the keys) in `for_each`. Accessing specific information then, like the ARN as before, requires a different sytnax `value = values(aws_iam_user.example)[*].arn` for our `output` variable. See the code.
    - The fact that `for_each` creates maps is a big deal compared to `count`! Because it creates a map, terraform doesn't depend on the indexing of a list if we make changes as before, so we can safely remove an element from the map without the concerns we had before of editing the list! For this reason it may be preferable to choose `for_each` over `count` to create multiple copies of a `resource`.

